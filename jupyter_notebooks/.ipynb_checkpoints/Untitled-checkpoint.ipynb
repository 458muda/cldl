{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c201fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "from osgeo import gdal\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "#import cv2\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import Sequence\n",
    "#import albumentations as A\n",
    "import sklearn\n",
    "import segmentation_models\n",
    "import argparse\n",
    "\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "#from keras.utils.np_utils import to_categorical\n",
    "# from tensorflow.keras.utils import multi_gpu_model, plot_model\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7086f52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               bands  \\\n",
      "0  /workspace/_libs/dl_library/ecuador extensive/...   \n",
      "1  /workspace/_libs/dl_library/ecuador extensive/...   \n",
      "2  /workspace/_libs/dl_library/ecuador extensive/...   \n",
      "3  /workspace/_libs/dl_library/ecuador extensive/...   \n",
      "4  /workspace/_libs/dl_library/ecuador extensive/...   \n",
      "\n",
      "                                              labels  \n",
      "0  /workspace/_libs/dl_library/ecuador extensive/...  \n",
      "1  /workspace/_libs/dl_library/ecuador extensive/...  \n",
      "2  /workspace/_libs/dl_library/ecuador extensive/...  \n",
      "3  /workspace/_libs/dl_library/ecuador extensive/...  \n",
      "4  /workspace/_libs/dl_library/ecuador extensive/...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "type_list = ['ecuador extensive', 'integrated mangrove', 'intensive', 'long lot extensive', 'smallholder extensive AP']\n",
    "\n",
    "data_path = '/workspace/_libs/dl_library/'\n",
    "df = pd.DataFrame(columns = [\"bands\", \"labels\"])\n",
    "bands_list = []\n",
    "labels_list = []\n",
    "\n",
    "for pond_type in type_list:\n",
    "    folder_path = os.path.join(data_path,pond_type)\n",
    "    bands_path = f'{folder_path}/pond_{pond_type}_bands'\n",
    "    labels_path = f'{folder_path}/pond_{pond_type}_label'\n",
    "    \n",
    "    foo1 = [os.path.join(bands_path, x) for x in os.listdir(bands_path)]\n",
    "    foo1.sort()\n",
    "\n",
    "    for data in foo1:\n",
    "        bands_list.append(data)\n",
    "        \n",
    "    foo2 = [os.path.join(labels_path, x) for x in os.listdir(labels_path)]\n",
    "    foo2.sort()\n",
    "\n",
    "    for data2 in foo2:\n",
    "        labels_list.append(data2)\n",
    "    \n",
    "\n",
    "df[\"bands\"] = bands_list\n",
    "df[\"labels\"] = labels_list\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "#df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f81f0696-8345-4ec9-9c87-9f6d75fce8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('check1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b64cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[:5000]\n",
    "val_df = df[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f321f35-be6c-4138-bb65-b4b6ab191862",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('pond_train.csv')\n",
    "val_df.to_csv('pond_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfabc8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bands\"][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"labels\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3788347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bands(path):\n",
    "    band_array = []\n",
    "    file = gdal.Open(path)\n",
    "    res_array = np.zeros((256, 256, 6))\n",
    "    for num in range(6):\n",
    "        array = np.array(file.GetRasterBand(num+1).ReadAsArray())\n",
    "        res_array[:,:,num] = array\n",
    "    band_array.append(res_array)\n",
    "    del file\n",
    "    return np.array(band_array).squeeze()\n",
    "\n",
    "def read_labels(path):\n",
    "    label_array = []\n",
    "    file = gdal.Open(path)\n",
    "    array = np.array(file.GetRasterBand(1).ReadAsArray())\n",
    "    label_array.append(array)\n",
    "    del file\n",
    "\n",
    "    return np.array(label_array).squeeze()\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "  def __init__(self, data_csv_path, batch_size,num_bands=6, transform = None):\n",
    "    _data = pd.read_csv(data_csv_path)\n",
    "    self.path_list = _data['bands'].tolist()\n",
    "    self.labels_list = _data['labels'].tolist()\n",
    "    self.batch_size = batch_size\n",
    "    self.transform = transform\n",
    "    self.num_bands = num_bands\n",
    "    \n",
    "\n",
    "  def __len__(self):\n",
    "    return int(np.floor(len(self.path_list) / self.batch_size))\n",
    "\n",
    "  def __getitem__(self,index):\n",
    "    # print('working on batch ',index)\n",
    "    batch_bands_paths = self.path_list[index*self.batch_size:(index+1)*self.batch_size]\n",
    "    batch_labels_paths = self.labels_list[index*self.batch_size:(index+1)*self.batch_size]\n",
    "    \n",
    "\n",
    "    x = np.empty((self.batch_size, 256, 256, self.num_bands), dtype=np.float32)\n",
    "    l = np.empty((self.batch_size, 256, 256), dtype=np.float32)\n",
    "\n",
    "    if self.transform is None:\n",
    "        for idx, data in enumerate(zip(batch_bands_paths,batch_labels_paths)):\n",
    "            b_path = data[0]\n",
    "            l_path = data[1]\n",
    "            x[idx] = read_bands(b_path)\n",
    "            l[idx] = read_labels(l_path)\n",
    "    else:\n",
    "        for idx, data in enumerate(zip(batch_bands_paths,batch_labels_paths)):\n",
    "            b_path = data[0]\n",
    "            l_path = data[1]\n",
    "            image = read_bands(b_path)\n",
    "            masks = read_labels(l_path)\n",
    "\n",
    "            transformed = self.transform(image=image, masks=masks)\n",
    "            x[idx] = transformed['image']\n",
    "            l[idx] = transformed['masks']\n",
    "\n",
    "\n",
    "    return x,l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7beed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_unet(input_height, input_width, bandNum):\n",
    "    inputs = Input((input_height,input_width, bandNum))\n",
    "    # Block one\n",
    "    # (256, 256, numBands) -> (256, 256, 64)\n",
    "    conv1 = BatchNormalization()(Conv2D(32, 3, padding='same', name='Conv1_1', kernel_initializer='he_normal')(inputs))\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    conv1 = BatchNormalization()(Conv2D(32, 3, padding='same', name='Conv1_2', kernel_initializer='he_normal')(conv1))\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    # (256, 256, 64) -> (128, 128, 64)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    # Block Two\n",
    "    # (128, 128, 64) -> (128, 128, 128)\n",
    "    conv2 = BatchNormalization()(Conv2D(64, 3, padding='same', name='Conv2_1', kernel_initializer='he_normal')(pool1))\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    conv2 = BatchNormalization()(Conv2D(64, 3, padding='same', name='Conv2_2', kernel_initializer='he_normal')(conv2))\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    # (128, 128, 128) -> (64, 64, 128)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # Block three\n",
    "    # (64, 64, 128) -> (64, 64, 256)\n",
    "    conv3 = BatchNormalization()(Conv2D(128, 3, padding='same', name='Conv3_1', kernel_initializer='he_normal')(pool2))\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    conv3 = BatchNormalization()(Conv2D(128, 3, padding='same', name='Conv3_2', kernel_initializer='he_normal')(conv3))\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    # (64, 64, 256) -> ( 32, 32, 256)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    # Block four\n",
    "    # (32, 32, 256) -> (32, 32, 512)\n",
    "    conv4 = BatchNormalization()(Conv2D(256, 3, padding='same', name='Conv4_1', kernel_initializer='he_normal')(pool3))\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    conv4 = BatchNormalization()(Conv2D(256, 3, padding='same', name='Conv4_2', kernel_initializer='he_normal')(conv4))\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    # (32, 32, 512) -> (16, 16, 512)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    # Block five\n",
    "    # (16, 16, 512) -> (16, 16, 1024)\n",
    "    conv5 = BatchNormalization()(Conv2D(512, 3, padding='same', name='Conv5_1', kernel_initializer='he_normal')(pool4))\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "    conv5 = BatchNormalization()(Conv2D(512, 3, padding='same', name='Conv5_2', kernel_initializer='he_normal')(conv5))\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "    \n",
    "    ## Decoder \n",
    "    # Block six\n",
    "    # (16, 16, 1024) -> (32, 32, 1024) -> (32, 32, 512)\n",
    "    up6 = Conv2DTranspose(256, (4, 4), strides=(2, 2), name = 'Conv6_1', padding='same')(conv5)\n",
    "    # (32, 32, 512) -> (32, 32, 1024)\n",
    "    merge6 = concatenate([conv4,up6],axis = 3)   \n",
    "    # (32, 32, 1024) -> (32, 32, 512)\n",
    "    conv6 = (Conv2D(256, 3,  padding = 'same', name = 'Conv6_2', kernel_initializer = 'he_normal')(merge6))\n",
    "    conv6 = Activation('relu')(conv6) \n",
    "    conv6 = (Conv2D(256, 3, padding = 'same', name = 'Conv6_3', kernel_initializer = 'he_normal')(conv6))\n",
    "    conv6 = Activation('relu')(conv6) \n",
    "    \n",
    "    # Block seven \n",
    "    # (32, 32, 512) -> (64, 64, 512) -> (64, 64, 256)\n",
    "    up7 = Conv2DTranspose(128, (4, 4), strides=(2, 2), name = 'Conv7_1', padding='same')(conv6)\n",
    "    # (64, 64, 256) -> (64, 64, 512)\n",
    "    merge7 = concatenate([conv3,up7],axis = 3)\n",
    "    # (64, 64, 512) -> (64, 64, 256)\n",
    "    conv7 = (Conv2D(128, 3,  padding = 'same', name = 'Conv7_2', kernel_initializer = 'he_normal')(merge7))\n",
    "    conv7 = Activation('relu')(conv7)          \n",
    "    conv7 = (Conv2D(128, 3, padding = 'same', name = 'Conv7_3', kernel_initializer = 'he_normal')(conv7))\n",
    "    conv7 = Activation('relu')(conv7)  \n",
    "                       \n",
    "    # Block eight \n",
    "    # (64, 64, 256) -> (128, 128, 256) -> (128, 128, 128)\n",
    "    up8 = Conv2DTranspose(64, (4, 4), strides=(2, 2), name = 'Conv8_1', padding='same')(conv7)\n",
    "    # (128, 128, 128) -> (128, 128, 256)\n",
    "    merge8 = concatenate([conv2,up8],axis = 3)   \n",
    "    # (128, 128, 256) -> (128, 128, 128)\n",
    "    conv8 = (Conv2D(64, 3, padding = 'same', name = 'Conv8_2', kernel_initializer = 'he_normal')(merge8))\n",
    "    conv8 = Activation('relu')(conv8)                     \n",
    "    conv8 = (Conv2D(64, 3,  padding = 'same', name = 'Conv8_3', kernel_initializer = 'he_normal')(conv8))\n",
    "    conv8 = Activation('relu')(conv8)  \n",
    "    \n",
    "    # Block nine \n",
    "    # (128, 128, 128) -> (256, 256, 128) -> (256, 256, 64)\n",
    "    up9 = Conv2DTranspose(32, (4, 4), strides=(2, 2), name = 'Conv9_1', padding='same')(conv8)\n",
    "    # (256, 256, 64) -> (256, 256, 128)\n",
    "    merge9 = concatenate([conv1,up9],axis = 3)\n",
    "    # (256, 256, 128) -> (256, 256, 64)                  \n",
    "    conv9 = (Conv2D(32, 3, padding = 'same',name = 'Conv9_2', kernel_initializer = 'he_normal')(merge9))\n",
    "    conv9 = Activation('relu')(conv9)                   \n",
    "    conv9 = (Conv2D(32, 3, padding = 'same', name = 'Conv9_3', kernel_initializer = 'he_normal')(conv9))\n",
    "    conv9 = Activation('relu')(conv9)  \n",
    "    \n",
    "    # (256, 256, 64) -> (256, 256, 64)\n",
    "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "    model = Model(inputs, outputs = conv10)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af4a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c69d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = binary_unet(256,256,6)\n",
    "#print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f9a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_csv = 'pond_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = segmentation_models.losses.BinaryFocalLoss()\n",
    "adam_opt = optimizers.Adam(lr=1E-4)\n",
    "model_1.compile(loss=loss,optimizer = adam_opt,metrics=['accuracy',segmentation_models.metrics.IOUScore()])\n",
    "train_data = DataGenerator(train_data_csv,4)\n",
    "model_1.fit(train_data,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4de68a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
